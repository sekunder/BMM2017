========== BEGIN TRAINING ==========
Training network on 20170829133103
Loading MNIST data for training
Embedding images into 64 x 64 canvases
Before enlarging: x_train.shape: (60000, 28, 28, 1)
After englarging: x_train.shape: (60000, 64, 64, 1)
Saving training object positions: /Users/sekunder/python/BMM2017/model/obj_pos_train_20170829133103
Saving testing object positions:  /Users/sekunder/python/BMM2017/model/obj_pos_test_20170829133103
--- MODEL SUMMARY ---
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 64, 64, 16)        160       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 32)        4640      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 4096)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              4195328   
_________________________________________________________________
dense_2 (Dense)              (None, 10)                10250     
_________________________________________________________________
activation_1 (Activation)    (None, 10)                0         
=================================================================
Total params: 4,228,874
Trainable params: 4,228,874
Non-trainable params: 0
_________________________________________________________________
None
Training network [batch size: 128, epochs: 10]
Train on 60000 samples, validate on 10000 samples
Epoch 1/10
434s - loss: 1.0405 - acc: 0.6474 - val_loss: 0.2712 - val_acc: 0.9141
Epoch 2/10
410s - loss: 0.2053 - acc: 0.9380 - val_loss: 0.1414 - val_acc: 0.9571
Epoch 3/10
410s - loss: 0.1312 - acc: 0.9602 - val_loss: 0.1173 - val_acc: 0.9617
Epoch 4/10
409s - loss: 0.0966 - acc: 0.9706 - val_loss: 0.0962 - val_acc: 0.9701
Epoch 5/10
409s - loss: 0.0760 - acc: 0.9762 - val_loss: 0.0907 - val_acc: 0.9703
Epoch 6/10
410s - loss: 0.0600 - acc: 0.9816 - val_loss: 0.0842 - val_acc: 0.9725
Epoch 7/10
411s - loss: 0.0484 - acc: 0.9849 - val_loss: 0.0803 - val_acc: 0.9731
Epoch 8/10
411s - loss: 0.0383 - acc: 0.9882 - val_loss: 0.0791 - val_acc: 0.9762
Epoch 9/10
411s - loss: 0.0316 - acc: 0.9899 - val_loss: 0.0828 - val_acc: 0.9734
Epoch 10/10
410s - loss: 0.0249 - acc: 0.9926 - val_loss: 0.0823 - val_acc: 0.9760
Saving model: /Users/sekunder/python/BMM2017/model/model20170829133103.h5

Test loss: 0.0823290023222
Test accuracy (%): 97.6
----------  END TRAINING  ----------
============================== BEGIN TRAINING ==============================
Training network on 20170829151236
Loading MNIST data for training
Embedding images into 64 x 64 canvases
Before enlarging: x_train.shape: (60000, 28, 28, 1)
After englarging: x_train.shape: (60000, 64, 64, 1)
Saving training object positions: /Users/sekunder/python/BMM2017/model/obj_pos_train_20170829151236
Saving testing object positions:  /Users/sekunder/python/BMM2017/model/obj_pos_test_20170829151236
--- MODEL SUMMARY ---
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 64, 64, 16)        160       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 32)        4640      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 8, 8, 64)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 4096)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              4195328   
_________________________________________________________________
dense_2 (Dense)              (None, 10)                10250     
_________________________________________________________________
activation_1 (Activation)    (None, 10)                0         
=================================================================
Total params: 4,228,874
Trainable params: 4,228,874
Non-trainable params: 0
_________________________________________________________________
None
Training network [batch size: 128, epochs: 10]
Train on 60000 samples, validate on 10000 samples
Epoch 1/10
428s - loss: 1.0451 - acc: 0.6419 - val_loss: 0.2539 - val_acc: 0.9237
Epoch 2/10
416s - loss: 0.2387 - acc: 0.9266 - val_loss: 0.1444 - val_acc: 0.9544
Epoch 3/10
416s - loss: 0.1603 - acc: 0.9513 - val_loss: 0.1237 - val_acc: 0.9592
Epoch 4/10
416s - loss: 0.1266 - acc: 0.9609 - val_loss: 0.1165 - val_acc: 0.9629
Epoch 5/10
416s - loss: 0.1055 - acc: 0.9677 - val_loss: 0.0830 - val_acc: 0.9739
Epoch 6/10
416s - loss: 0.0918 - acc: 0.9719 - val_loss: 0.0698 - val_acc: 0.9765
Epoch 7/10
415s - loss: 0.0803 - acc: 0.9746 - val_loss: 0.0704 - val_acc: 0.9773
Epoch 8/10
417s - loss: 0.0708 - acc: 0.9776 - val_loss: 0.0688 - val_acc: 0.9792
Epoch 9/10
415s - loss: 0.0661 - acc: 0.9792 - val_loss: 0.0686 - val_acc: 0.9774
Epoch 10/10
415s - loss: 0.0592 - acc: 0.9811 - val_loss: 0.0618 - val_acc: 0.9799
Saving model: /Users/sekunder/python/BMM2017/model/model20170829151236.h5

Test loss: 0.0618131687981
Test accuracy (%): 97.99
------------------------------  END TRAINING  ------------------------------
============================== BEGIN TRAINING ==============================
Training network on 20170829181155
Creating directory: /Users/sekunder/python/BMM2017/model/20170829181155
Loading MNIST data for training
Embedding images into 64 x 64 canvases
Before enlarging: x_train.shape: (60000, 28, 28, 1)
After englarging: x_train.shape: (60000, 64, 64, 1)
Saving training object positions: /Users/sekunder/python/BMM2017/model/20170829181155/obj_pos_train_20170829181155
Saving testing object positions:  /Users/sekunder/python/BMM2017/model/20170829181155/obj_pos_test_20170829181155
--- MODEL SUMMARY ---
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 64, 64, 16)        160       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 32)        4640      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 8, 8, 64)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 4096)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              4195328   
_________________________________________________________________
dense_2 (Dense)              (None, 10)                10250     
_________________________________________________________________
activation_1 (Activation)    (None, 10)                0         
=================================================================
Total params: 4,228,874
Trainable params: 4,228,874
Non-trainable params: 0
_________________________________________________________________
None
Extra info: [dropout rate: 0.500000]
Training network [batch size: 128, epochs: 10]...
Train on 60000 samples, validate on 10000 samples
Epoch 1/10
512s - loss: 1.1144 - acc: 0.6165 - val_loss: 0.3185 - val_acc: 0.9019
Epoch 2/10
489s - loss: 0.2858 - acc: 0.9141 - val_loss: 0.1649 - val_acc: 0.9495
Epoch 3/10
489s - loss: 0.2072 - acc: 0.9377 - val_loss: 0.1170 - val_acc: 0.9631
Epoch 4/10
490s - loss: 0.1724 - acc: 0.9472 - val_loss: 0.1030 - val_acc: 0.9685
Epoch 5/10
489s - loss: 0.1492 - acc: 0.9542 - val_loss: 0.0910 - val_acc: 0.9713
Epoch 6/10
489s - loss: 0.1368 - acc: 0.9586 - val_loss: 0.0918 - val_acc: 0.9690
Epoch 7/10
489s - loss: 0.1242 - acc: 0.9608 - val_loss: 0.0720 - val_acc: 0.9759
Epoch 8/10
488s - loss: 0.1139 - acc: 0.9650 - val_loss: 0.0699 - val_acc: 0.9790
Epoch 9/10
489s - loss: 0.1076 - acc: 0.9665 - val_loss: 0.0676 - val_acc: 0.9783
Epoch 10/10
488s - loss: 0.1021 - acc: 0.9678 - val_loss: 0.0654 - val_acc: 0.9791
Saving model: /Users/sekunder/python/BMM2017/model/20170829181155/model_20170829181155.h5

Test loss: 0.0653983353178
Test accuracy (%): 97.91
------------------------------  END TRAINING  ------------------------------
============================== BEGIN TRAINING ==============================
Training network on 20170831123503
Creating directory: /Users/sekunder/python/BMM2017/model/20170831123503
Loading MNIST data for training
Embedding images into 64 x 64 canvases
* bg_noise is uniform
Before enlarging: x_train.shape: (60000, 28, 28, 1)
After englarging: x_train.shape: (60000, 64, 64, 1)
Saving training object positions: /Users/sekunder/python/BMM2017/model/20170831123503/obj_pos_train_20170831123503
Saving testing object positions:  /Users/sekunder/python/BMM2017/model/20170831123503/obj_pos_test_20170831123503
--- MODEL SUMMARY ---
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 64, 64, 16)        160       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 32)        4640      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 8, 8, 64)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 4096)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              4195328   
_________________________________________________________________
dense_2 (Dense)              (None, 10)                10250     
_________________________________________________________________
activation_1 (Activation)    (None, 10)                0         
=================================================================
Total params: 4,228,874
Trainable params: 4,228,874
Non-trainable params: 0
_________________________________________________________________
None
Extra info: [dropout rate: 0.500000]
Training network [batch size: 128, epochs: 10]...
Train on 60000 samples, validate on 10000 samples
Epoch 1/10
590s - loss: 2.3027 - acc: 0.1101 - val_loss: 2.3006 - val_acc: 0.1135
Epoch 2/10
545s - loss: 2.2814 - acc: 0.1334 - val_loss: 2.1905 - val_acc: 0.1885
Epoch 3/10
510s - loss: 2.0731 - acc: 0.2413 - val_loss: 1.9177 - val_acc: 0.3425
Epoch 4/10
510s - loss: 1.6667 - acc: 0.4113 - val_loss: 1.2562 - val_acc: 0.5956
Epoch 5/10
510s - loss: 1.2112 - acc: 0.5937 - val_loss: 0.8475 - val_acc: 0.7457
Epoch 6/10
510s - loss: 0.9388 - acc: 0.6919 - val_loss: 0.7445 - val_acc: 0.7649
Epoch 7/10
509s - loss: 0.7783 - acc: 0.7482 - val_loss: 0.5155 - val_acc: 0.8418
Epoch 8/10
511s - loss: 0.6675 - acc: 0.7857 - val_loss: 0.4460 - val_acc: 0.8647
Epoch 9/10
556s - loss: 0.6017 - acc: 0.8052 - val_loss: 0.3987 - val_acc: 0.8797
Epoch 10/10
536s - loss: 0.5502 - acc: 0.8257 - val_loss: 0.3623 - val_acc: 0.8910
Saving model: /Users/sekunder/python/BMM2017/model/20170831123503/model_20170831123503.h5

Test loss: 0.362338971639
Test accuracy (%): 89.1
Saving metadata: /Users/sekunder/python/BMM2017/model/20170831123503/metadata_20170831123503.json
------------------------------  END TRAINING  ------------------------------
============================== BEGIN TRAINING ==============================
Training network on 20170831151950
Creating directory: /Users/sekunder/python/BMM2017/model/20170831151950
Loading MNIST data for training
Embedding images into 64 x 64 canvases
* bg_noise is normal
Before enlarging: x_train.shape: (60000, 28, 28, 1)
After englarging: x_train.shape: (60000, 64, 64, 1)
Saving training object positions: /Users/sekunder/python/BMM2017/model/20170831151950/obj_pos_train_20170831151950
Saving testing object positions:  /Users/sekunder/python/BMM2017/model/20170831151950/obj_pos_test_20170831151950
--- MODEL SUMMARY ---
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 64, 64, 16)        160       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 32, 32, 16)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 32, 32, 32)        4640      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 8, 8, 64)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 4096)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              4195328   
_________________________________________________________________
dense_2 (Dense)              (None, 10)                10250     
_________________________________________________________________
activation_1 (Activation)    (None, 10)                0         
=================================================================
Total params: 4,228,874
Trainable params: 4,228,874
Non-trainable params: 0
_________________________________________________________________
None
Extra info: [dropout rate: 0.500000]
Training network [batch size: 128, epochs: 10]...
Train on 60000 samples, validate on 10000 samples
Epoch 1/10
528s - loss: 1.4468 - acc: 0.4928 - val_loss: 0.3953 - val_acc: 0.8909
Epoch 2/10
527s - loss: 0.4091 - acc: 0.8743 - val_loss: 0.2086 - val_acc: 0.9398
Epoch 3/10
534s - loss: 0.2829 - acc: 0.9138 - val_loss: 0.1616 - val_acc: 0.9544
Epoch 4/10
521s - loss: 0.2311 - acc: 0.9290 - val_loss: 0.1344 - val_acc: 0.9597
Epoch 5/10
606s - loss: 0.1988 - acc: 0.9394 - val_loss: 0.1215 - val_acc: 0.9637
Epoch 6/10
529s - loss: 0.1769 - acc: 0.9452 - val_loss: 0.1018 - val_acc: 0.9691
Epoch 7/10
522s - loss: 0.1615 - acc: 0.9501 - val_loss: 0.0918 - val_acc: 0.9710
Epoch 8/10
536s - loss: 0.1463 - acc: 0.9544 - val_loss: 0.0824 - val_acc: 0.9739
Epoch 9/10
583s - loss: 0.1369 - acc: 0.9577 - val_loss: 0.0895 - val_acc: 0.9714
Epoch 10/10
530s - loss: 0.1268 - acc: 0.9609 - val_loss: 0.0887 - val_acc: 0.9718
Saving model: /Users/sekunder/python/BMM2017/model/20170831151950/model_20170831151950.h5

Test loss: 0.0886616973273
Test accuracy (%): 97.18
Saving metadata: /Users/sekunder/python/BMM2017/model/20170831151950/metadata_20170831151950.json
------------------------------  END TRAINING  ------------------------------
